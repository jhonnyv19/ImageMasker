{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from einops import rearrange\n",
        "\n",
        "if '..' not in sys.path:\n",
        "    sys.path.append('..')\n",
        "    \n",
        "from src.lit_models.lit_masking_model import LitMaskingModel\n",
        "from src.datasets.cifar10 import CIFAR10Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHECKPOINT_PATH = \"../weights/masker-cifar10.ckpt\"\n",
        "MAE_CHECKPOINT_PATH = \"../weights/mae-cifar10.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "masking_model_state_dict = torch.load(CHECKPOINT_PATH)\n",
        "mae_model_state_dict = torch.load(MAE_CHECKPOINT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hyperparams = masking_model_state_dict['hyper_parameters']\n",
        "hyperparams = {k: v for k, v in hyperparams.items() if not k.startswith('_')}\n",
        "hyperparams['mae_checkpoint_path'] = MAE_CHECKPOINT_PATH\n",
        "state_dict = masking_model_state_dict['state_dict']\n",
        "\n",
        "new_state_dict = {}\n",
        "for key, value in state_dict.items():\n",
        "    # remove any instance of _orig_mod.\n",
        "    if '_orig_mod.' in key:\n",
        "        key = key.replace('_orig_mod.', '')\n",
        "    new_state_dict[key] = value\n",
        "\n",
        "\n",
        "model = LitMaskingModel(**hyperparams)\n",
        "model.load_state_dict(new_state_dict)\n",
        "model.eval()\n",
        "model.cuda()\n",
        "print(\"Model loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "NUM_ROWS = 16\n",
        "print(\"Loading CIFAR10 dataset...\")\n",
        "datamodule = CIFAR10Data(data_dir=\"../data\", batch_size=NUM_ROWS)\n",
        "datamodule.prepare_data()\n",
        "datamodule.setup(stage=\"fit\")\n",
        "\n",
        "# Get a batch of images\n",
        "val_loader = datamodule.val_dataloader()\n",
        "images, _ = next(iter(val_loader))\n",
        "images = images.to(model.device)\n",
        "\n",
        "print(f\"Loaded {images.shape[0]} images for visualization.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Indices for the \"cherry-picked\" visualization (the \"good\" results)\n",
        "cherry_picked_indices = [1, 3, 6, 9, 11, 13, 15] # Example indices, you can change this\n",
        "\n",
        "# Take remaining indices\n",
        "all_indices = list(range(NUM_ROWS))\n",
        "remaining_indices = [i for i in all_indices if i not in cherry_picked_indices]\n",
        "\n",
        "print(f\"Cherry-picked indices: {cherry_picked_indices}\")\n",
        "print(f\"Remaining indices: {remaining_indices}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run inference to get model outputs on all 16 images\n",
        "print(f\"Running inference with tau: {model.tau}\")\n",
        "with torch.no_grad():\n",
        "    x_recon, mask_probs = model(images)\n",
        "    x_recon = torch.clamp(x_recon, 0, 1)\n",
        "\n",
        "print(\"Inference complete.\")\n",
        "print(f\"  - Reconstructions tensor shape: {x_recon.shape}\")\n",
        "print(f\"  - Mask probabilities tensor shape: {mask_probs.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    # Upsample masks from patch resolution to image resolution\n",
        "num_patches = mask_probs.shape[1]\n",
        "num_patches_per_side = int(np.sqrt(num_patches))\n",
        "image_size = model.hparams.image_size\n",
        "\n",
        "# Reshape from (B, N) to (B, H', W') where H' and W' are patch dimensions\n",
        "mask_spatial = mask_probs.view(-1, num_patches_per_side, num_patches_per_side)\n",
        "# Add a channel dimension: (B, 1, H', W')\n",
        "mask_spatial = mask_spatial.unsqueeze(1)\n",
        "# Upsample to image size (B, 1, H, W)\n",
        "mask_image = F.interpolate(\n",
        "    mask_spatial,\n",
        "    size=(image_size, image_size),\n",
        "    mode='nearest'\n",
        ")\n",
        "\n",
        "# Move tensors to CPU and convert to numpy\n",
        "images_np = images.cpu().numpy().astype(np.float32)\n",
        "x_recon_np = x_recon.cpu().numpy().astype(np.float32)\n",
        "mask_image_np = mask_image.cpu().numpy().astype(np.float32)\n",
        "\n",
        "print(\"Data prepared for visualization.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_and_save_visualization(indices, images_np, x_recon_np, mask_image_np, filename):\n",
        "    \"\"\"\n",
        "    Generates and saves a visualization for a given set of indices.\n",
        "\n",
        "    Args:\n",
        "        indices (list): List of indices to include in the visualization.\n",
        "        images_np (np.ndarray): Numpy array of all original images.\n",
        "        x_recon_np (np.ndarray): Numpy array of all reconstructed images.\n",
        "        mask_image_np (np.ndarray): Numpy array of all mask images.\n",
        "        filename (str): The filename to save the plot as.\n",
        "    \"\"\"\n",
        "    num_rows = len(indices)\n",
        "    if num_rows == 0:\n",
        "        print(f\"No indices to visualize for {filename}.\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, 4, figsize=(12, 3 * num_rows))\n",
        "    fig.suptitle(f\"Model Visualization - {filename.replace('.png', '').replace('_', ' ').title()}\", fontsize=16)\n",
        "\n",
        "    titles = [\"Original Image\", \"Generated Mask\", \"Mask Overlay\", \"Composite Image\"]\n",
        "    \n",
        "    # Handle single row case\n",
        "    if num_rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        # 1. Original Image\n",
        "        ax = axes[i, 0]\n",
        "        ax.imshow(np.transpose(images_np[idx], (1, 2, 0)))\n",
        "        ax.set_title(titles[0] if i == 0 else \"\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        # 2. Generated Mask (white = transmitted, black = masked)\n",
        "        ax = axes[i, 1]\n",
        "        ax.imshow(mask_image_np[idx, 0], cmap='gray')\n",
        "        ax.set_title(titles[1] if i == 0 else \"\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        # 3. Mask Overlay (red overlay on masked regions)\n",
        "        ax = axes[i, 2]\n",
        "        original_img_permuted = np.transpose(images_np[idx], (1, 2, 0))\n",
        "        masking_prob = 1.0 - mask_image_np[idx, 0]\n",
        "        red_overlay = np.zeros_like(original_img_permuted)\n",
        "        red_overlay[..., 0] = 1.0\n",
        "        alpha = 0.6 * masking_prob[..., np.newaxis]\n",
        "        overlayed_image = (1 - alpha) * original_img_permuted + alpha * red_overlay\n",
        "        overlayed_image = np.clip(overlayed_image, 0, 1)\n",
        "        ax.imshow(overlayed_image)\n",
        "        ax.set_title(titles[2] if i == 0 else \"\")\n",
        "        ax.axis('off')\n",
        "\n",
        "        # 4. Composite Image (what receiver sees)\n",
        "        ax = axes[i, 3]\n",
        "        original_img = np.transpose(images_np[idx], (1, 2, 0))\n",
        "        recon_img = np.transpose(x_recon_np[idx], (1, 2, 0))\n",
        "        transmission_prob = mask_image_np[idx, 0][..., np.newaxis]\n",
        "        composite_img = (transmission_prob * original_img + (1 - transmission_prob) * recon_img)\n",
        "        composite_img = np.clip(composite_img, 0, 1)\n",
        "        ax.imshow(composite_img)\n",
        "        ax.set_title(titles[3] if i == 0 else \"\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    \n",
        "    # Save the figure\n",
        "    save_path = os.path.join(\"..\", \"assets\", filename)\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"Visualization saved to {save_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "# --- Create and save both visualizations ---\n",
        "\n",
        "# Create and save the visualization for cherry-picked images (\"good\" results)\n",
        "print(\"\\nCreating cherry-picked visualization...\")\n",
        "create_and_save_visualization(\n",
        "    cherry_picked_indices,\n",
        "    images_np,\n",
        "    x_recon_np,\n",
        "    mask_image_np,\n",
        "    \"good_visualization.png\"\n",
        ")\n",
        "\n",
        "# Create and save the visualization for the remaining images (\"bad\" results)\n",
        "print(\"\\nCreating remaining visualization...\")\n",
        "create_and_save_visualization(\n",
        "    remaining_indices,\n",
        "    images_np,\n",
        "    x_recon_np,\n",
        "    mask_image_np,\n",
        "    \"bad_visualization.png\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
